{
    "version": "1.0.0",
    "name": "DeepSeek R1 Distill Qwen 32B (vLLM)",
    "container": {
        "image": "vllm/vllm-openai",
        "tag": "v0.6.2@sha256:730ef3d3c17a217b34cfdbfd99be80b3f459e37ef2fc0c5c43ba70752dad08ae",
        "command": ["bash","-c"],
        "arguments": ["vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"]
    },
    "resources": {
        "cpu": 32,
        "memory": "128Gi",
        "ephemeralStorage": "50Gi",
        "gpu": {
            "cores": 1,
            "gpuRequests": [
                {
                    "gpuCode": "a100"
                },
                {
                    "gpuCode": "h100"
                }
            ]
        },
        "storage": [
            {
                "name": "shm",
                "size": "32Gi",
                "persistent": false,
                "class": "ram",
                "mount": "/dev/shm"
            },
            {
                "name": "data",
                "size": "100Gi",
                "persistent": true,
                "class": "beta3",
                "mount": "/root/.cache"
            }

        ]

    },
    "ports": [
        {
            "container": 8000,
            "external": 80,
            "protocol": "tcp"
        }
    ],
    "env": [
        {
            "name": "HF_TOKEN",
            "value": ""
        }
    ],
    "metadata": {
        "version": "1.0.0",
        "tags": ["AI", "LLM"],
        "description": "DeepSeek-R1-Distill models are fine-tuned based on open-source models, using samples generated by DeepSeek-R1. Running on vLLM."
    }
}
