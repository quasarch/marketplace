{
    "version": "1.0.0",
    "name": "DeepSeek R1 Distill Llama 70B",
    "container": {
        "image": "lmsysorg/sglang",
        "tag": "v0.4.1.post4-cu124-srt",
        "command": ["bash","-c"],
        "arguments": ["python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Llama-70B --tp 2 --trust-remote-code --host 0.0.0.0 --port 8000"]
    },
    "resources": {
        "cpu": 32,
        "memory": "128Gi",
        "ephemeralStorage": "50Gi",
        "gpu": {
            "cores": 2,
            "gpuRequests": [
                {
                    "gpuCode": "a100"
                },
                {
                    "gpuCode": "h100"
                }
            ]
        },
        "storage": [
            {
                "name": "shm",
                "size": "32Gi",
                "persistent": false,
                "class": "ram",
                "mount": "/dev/shm"
            },
            {
                "name": "data",
                "size": "200Gi",
                "persistent": true,
                "class": "beta3",
                "mount": "/root/.cache"
            }

        ]

    },
    "ports": [
        {
            "container": 8000,
            "external": 80,
            "protocol": "tcp"
        }
    ],
    "env": [
        {
            "name": "HF_TOKEN",
            "value": ""
        }
    ],
    "metadata": {
        "version": "1.0.0",
        "tags": ["AI", "LLM"],
        "description": "DeepSeek-R1-Distill models are fine-tuned based on open-source models, using samples generated by DeepSeek-R1. Running on sglang."
    }
}
